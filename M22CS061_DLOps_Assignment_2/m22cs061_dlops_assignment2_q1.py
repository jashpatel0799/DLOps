# -*- coding: utf-8 -*-
"""M22CS061_DLOps_Assignment2_Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FaRRfwxBS2glZ2FHG9Hqsft2dxW1tdGA
"""

!pip install -U torch==1.7.1 torchtext==0.4.0

# Reload environment
exit()

"""## Import require Libraries"""

import torch
import torchtext
from torchtext.data import Field, BucketIterator
import csv
import torch.nn as nn
from torchtext.datasets import TranslationDataset
from torchtext.data import TabularDataset
import random
import time
import matplotlib.pyplot as plt
import json
import numpy as np
import pandas as pd
import spacy
import re
from torch.utils.data import TensorDataset, DataLoader, Dataset
from torch.nn.utils.rnn import pad_sequence

from pathlib import Path
from google.colab import drive
drive.mount('/content/drive/')

from torchtext.data.utils import get_tokenizer
from collections import Counter
from torchtext.vocab import Vocab
from torchtext.utils import download_from_url, extract_archive
import io
from tqdm.auto import tqdm
from timeit import default_timer as timer

from typing import Tuple

import torch.nn.functional as F
from torch import Tensor

torchtext.__version__

import os
os.environ['PYTHONIOENCODING'] = 'utf-8'

"""## Device Agnostic code"""

device = 'cuda' if torch.cuda.is_available() else 'cpu'
device

"""## Get data"""

train_data = 'drive/MyDrive/Course/Sem2/DLOps/data/hi_train.tsv'
test_data = 'drive/MyDrive/Course/Sem2/DLOps/data/hi_test.tsv'
val_data = 'drive/MyDrive/Course/Sem2/DLOps/data/hi_dev.tsv'

# source_vocab = Field(tokenize=list, init_token='<sos>', eos_token='<eos>')
# target_vocab = Field(tokenize=list, init_token='<sos>', eos_token='<eos>')



source_field = Field(tokenize=list, init_token='<sos>', eos_token='<eos>')
target_field = Field(tokenize=list, init_token='<sos>', eos_token='<eos>')

# train_dataset = TabularDataset(path=train_data, format='tsv', fields=[('source', source_vocab), ('target', target_vocab)])
train_dataset = TabularDataset(path=train_data, format='tsv', fields=[('source', source_field), ('target', target_field)])

# train_dataset = train_dataset[0:10000]

"""### view dataset"""

train_df = df = pd.read_csv(train_data, sep = '\t', names = ['Hindi', 'English', 'num'])
train_df.head()

test_df = df = pd.read_csv(test_data, sep = '\t', names = ['Hindi', 'English', 'num'])
test_df.head()

val_df = df = pd.read_csv(val_data, sep = '\t', names = ['Hindi', 'English', 'num'])
val_df.head()

len(train_df.index), len(test_df.index), len(val_df.index)

train_df = train_df.dropna()
val_df = val_df.dropna()
test_df = test_df.dropna()

train, test, val = train_df.to_numpy(), test_df.to_numpy(), val_df.to_numpy()

train_labels, train_texts = train[:,0], train[:,1]
test_labels, test_texts = test[:,0], test[:,1]
val_labels, val_texts = val[:,0], val[:,1]

train_texts, train_labels

train_texts.shape

"""### make tokens"""

# type(train_dataset)

train_dataset[0].source

# data_tuples = [{"source": train_dataset[i].source, "target": train_dataset[i].target} for i in range(len(train_dataset))]

# print(data_tuples)
# # with open("data.json", "w") as f:
# #     json.dump(data_tuples, f)

# with open("data_tsv.tsv", "w", newline='') as f:
#     writer = csv.DictWriter(f, fieldnames=data_tuples[0].keys(), delimiter='\t')
#     writer.writeheader()
#     writer.writerows(data_tuples)

# train_dataset = TabularDataset(
#     path="data_tsv.tsv",  # Set to None as we are providing data directly
#     format="tsv",
#     fields={"source": ('source', source_field), "target": ('target', target_field)},
#     skip_header=False
# )

# type(train_dataset)

# len(train_dataset)

# train_dataset[10].source, type(train_dataset[0].target)

# for i in range(len(train_dataset)):
#   while '[' in train_dataset[i].source:
#     train_dataset[i].source.remove('[')

#   while "'" in train_dataset[i].source:
#     train_dataset[i].source.remove("'")

#   while ',' in train_dataset[i].source:
#     train_dataset[i].source.remove(",")

#   while ' ' in train_dataset[i].source:
#     train_dataset[i].source.remove(" ")

#   while ']' in train_dataset[i].source:
#     train_dataset[i].source.remove("]")


#   while '[' in train_dataset[i].target:
#     train_dataset[i].target.remove('[')

#   while "'" in train_dataset[i].target:
#     train_dataset[i].target.remove("'")

#   while ',' in train_dataset[i].target:
#     train_dataset[i].target.remove(",")

#   while ' ' in train_dataset[i].target:
#     train_dataset[i].target.remove(" ")

#   while ']' in train_dataset[i].target:
#     train_dataset[i].target.remove("]")

# source_vocab.build_vocab(train_dataset.source)
# target_vocab.build_vocab(train_dataset.target)
source_field.build_vocab(train_dataset.source)
target_field.build_vocab(train_dataset.target)

target_field.tokenize('Jash Patel'), target_field.tokenize('अंकुरण')

# hindi token
def hindi_alpha_tokenizer(text):
    # split the text into alphabetic tokens using regular expressions
    text = re.sub(r"[^ऀ-ॿ]+", " ", text)
    return [char for char in text]

# english token
def alpha_tokenizer(text):
    tokens = re.findall(r'\b[a-zA-Z]+\b', text)
    return tokens

def build_vocab(data, tokenizer):
  counter = Counter()
  for string_ in data:
    for s in string_:
      counter.update(tokenizer(s))
  return Vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])


# source_vocab = build_vocab(train_texts, alpha_tokenizer)
# target_vocab = build_vocab(train_labels, hindi_alpha_tokenizer)

"""### Build dataset"""

def data_process(source, target):

  data = []
  for (s, t) in zip(source, target):
    source_tensor_ = torch.tensor([source_field[token] for token in source_field(s)],
                            dtype=torch.long)
    target_tensor_ = torch.tensor([target_field[token] for token in target_field(t)],
                            dtype=torch.long)
    data.append((source_tensor_, target_tensor_))
  return data

# train_dataset = data_process(train_labels, train_texts)
# val_dataset = data_process(val_labels, val_texts)
# test_dataset = data_process(test_labels, test_texts)

"""## Iterator"""

BATCH_SIZE = 128
train_iter = BucketIterator(train_dataset, batch_size = BATCH_SIZE, device = device)

test_dataset = TabularDataset(path=test_data, format='tsv', fields=[('source', source_field), ('target', target_field)])
test_iter = BucketIterator(test_dataset, batch_size = BATCH_SIZE, device = device)

val_dataset = TabularDataset(path=val_data, format='tsv', fields=[('source', source_field), ('target', target_field)])
val_iter = BucketIterator(val_dataset, batch_size = BATCH_SIZE, device = device)

"""## Tarin and test loop"""

# # train
# def train_loop(model, data_iter, loss_fn, optimizer, device):
#   model.train()

#   train_loss, train_acc = 0, 0

#   for data in data_iter:
#     x_train, y_train = data.source, data.target

#     print(len(x_train), len(y_train))

#     if device == 'cuda':
#       x_train, y_train = x_train.to(device), y_train.to(device)

#     output = model(x_train, y_train)

#     print(output.shape, y_train.shape)

#     output = output[1:].reshape(-1, output.shape[-1])
#     y_train = y_train[1:].reshape(-1)

#     optimizer.zero_grad()

#     print(len(output), len(y_train))
#     loss = loss_fn(output, y_train)

#     loss.backward()

#     optimizer.step()

#     train_loss += loss
  
#   train_loss /= len(data_iter)

#   return train_loss, train_acc

# def test_loop(model, data_iter, loss_fn, device):

#   test_loss, test_acc = 0, 0

#   model.eval()
#   with torch.inference_mode():
#     for data in data_iter:

#       x_test, y_test = data.source, data.target

#       if device == 'cuda':
#         x_test, y_test = x_test.to(device), y_test.to(device)

#       output = model(x_test, y_test)

#       output = output[1:].reshape(-1, output.shape[2])
#       y_test = y_test[1:].reshape(-1)


#       loss = loss_fn(output, y_test)

#       test_loss += loss

#     test_loss /= len(data_iter)

#   return test_loss, test_acc

INPUT_DIM = len(source_field.vocab)
print(INPUT_DIM)
OUTPUT_DIM = len(target_field.vocab)
print(OUTPUT_DIM)

def train(model, data_iter, loss_fn, optimizer, device):
    
    train_loss = 0

    model.train()
        
    for data in data_iter:
        src = data.source
        trg = data.target
        # print(src.shape)
        # print(trg.shape)
        optimizer.zero_grad()
        
        output = model(src, trg)
        # print(output.shape)
        
        output_dim = output.shape[-1]
        
        output = output[1:].view(-1, output_dim)
        trg = trg[1:].view(-1)
        
        loss = loss_fn(output, trg)
        loss.backward()
        
        optimizer.step()

        train_loss += loss

           
    train_loss /= len(data_iter)

    return train_loss

# test
def test_loop(model, data_iter, loss_fn, device):

  test_loss = 0

  model.eval()
  with torch.no_grad():
    for data in data_iter:

      x_test, y_test = data.source, data.target

      if device == 'cuda':
        x_test, y_test = x_test.to(device), y_test.to(device)

      output = model(x_test, y_test)
      # print(output.shape)
      
      output_dim = output.shape[-1]
      
      output = output[1:].view(-1, output_dim)
      y_test = y_test[1:].view(-1)
      
      loss = loss_fn(output, y_test)

      test_loss += loss

    test_loss /= len(data_iter)

  return test_loss

"""## Plot Function"""

def plot_graph(train_losses, test_losses):
  plt.figure(figsize = (10, 8))
  # plt.subplot(1, 2, 1)
  plt.plot(range(len(train_losses)), train_losses, label = "Train Loss")
  plt.plot(range(len(test_losses)), test_losses, label = "Test Loss")
  plt.legend()
  plt.xlabel("Epoches")
  plt.ylabel("Loss")
  plt.show()

"""## Loss Function"""

pad_index = target_field.vocab.stoi['<pad>']
loss_fn = nn.CrossEntropyLoss(ignore_index = pad_index)

"""# A

## Build Model of LSTM

### Encoder
"""

class LSTMEncoder(nn.Module):
  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):
    super().__init__()
    self.input_size = input_size
    self.hidden_size = hidden_size
    self.num_layers = num_layers
    self.dropout = nn.Dropout(p)
    self.embedding = nn.Embedding(input_size, embedding_size)
    self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)
    

  def forward(self, x):
    embedding = self.dropout(self.embedding(x))
    ot, (h, c) = self.lstm(embedding)

    return h, c

"""### Decoder"""

class LSTMDecoder(nn.Module):
  def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p):
    super().__init__()
    self.hidden_size = hidden_size
    self.output_dim = output_size
    self.num_layers = num_layers
    self.dropout = nn.Dropout(p)
    self.embedding = nn.Embedding(output_size, embedding_size)
    self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)
    self.fc = nn.Linear(hidden_size, output_size)

  def forward(self, x, h, c):

    x = x.unsqueeze(0)

    embedding = self.dropout(self.embedding(x))

    ot, (h, c) = self.lstm(embedding, (h, c))

    predict = self.fc(ot.squeeze(0))

    # predict = predict.squeeze(0)

    return predict, h, c

"""### Seq2Seq """

class LSTMSeq2Seq(nn.Module):
  def __init__(self, encoder, decoder):
    super().__init__()
    self.encoder = encoder
    self.decoder = decoder

  def forward(self, source, target, teacher_force_ratio = 0.5):
    batch_size = target.shape[1]
    target_len = target.shape[0]

    trg_vocab_size = self.decoder.output_dim

    outputs = torch.zeros(target_len, batch_size, trg_vocab_size).to(device)

    h, c = self.encoder(source)

    x = target[0,:]

    for t in range(1, target_len):
      output, h, c = self.decoder(x, h, c)
      outputs[t] = output
      best_guess = output.argmax(1)

      x = target[t] if random.random() < teacher_force_ratio else best_guess

    return outputs

"""## Train LSTM Model"""

load_model = False
input_size_encoder = len(source_field.vocab)
input_size_decoder = len(target_field.vocab)
output_size = len(target_field.vocab)
encoder_embedding_size = 64
decoder_embedding_size = 64
hidden_size = 64
num_layers = 1
dropout_preb = 0.3

epoches = 10


train_loss_list, test_loss_list = [], []

torch.manual_seed(64)
torch.cuda.manual_seed(64)
lstm_encoder = LSTMEncoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, dropout_preb).to(device)
lstm_decoder = LSTMDecoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dropout_preb).to(device)
lstm_model = LSTMSeq2Seq(lstm_encoder, lstm_decoder).to(device)

optimizer = torch.optim.Adam(lstm_model.parameters(), lr = 1e-2)

start_time = timer()
torch.manual_seed(64)
torch.cuda.manual_seed(64)
for epoch in tqdm(range(epoches)):
  print(f'Epoch: {epoch+1} / {epoches}')

  train_loss = train(lstm_model, train_iter, loss_fn, optimizer, device)
  test_loss = test_loop(lstm_model, test_iter, loss_fn, device)

  train_loss_list.append(train_loss.item())
  test_loss_list.append(test_loss.item())

  print(f"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}")
  print()
  # print(f"Train Loss: {train_loss:.4f}")
end_time = timer()

print(f'Total Exe Time: {(end_time - start_time)} Sec')

plot_graph(train_loss_list, test_loss_list)

"""## Build Model of RNN

### Encoder
"""

class RNNEncoder(nn.Module):
  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):
    super().__init__()
    self.input_size = input_size
    self.embedding_size = embedding_size
    self.hidden_size = hidden_size
    self.num_layers = num_layers
    self.dropout = nn.Dropout(p)
    self.embedding = nn.Embedding(input_size, embedding_size)
    self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout=p)
    

  def forward(self, x):
    embedding = self.dropout(self.embedding(x))
    ot, h = self.rnn(embedding)

    return h

"""### Decoder"""

class RNNDecoder(nn.Module):
  def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p):
    super().__init__()
    self.input_size = input_size
    self.embedding_size = embedding_size
    self.hidden_size = hidden_size
    self.output_dim = output_size
    self.num_layers = num_layers
    self.dropout = nn.Dropout(p)

    self.embedding = nn.Embedding(output_size, embedding_size)
    self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout=p)
    self.fc = nn.Linear(hidden_size, output_size)

  def forward(self, x, h):

    x = x.unsqueeze(0)

    embedding = self.dropout(self.embedding(x))

    ot, h = self.rnn(embedding, h)

    predict = self.fc(ot.squeeze(0))

    # predict = predict.squeeze(0)

    return predict, h

"""### Seq2Seq"""

class RNNSeq2Seq(nn.Module):
  def __init__(self, encoder, decoder):
    super().__init__()
    self.encoder = encoder
    self.decoder = decoder

  def forward(self, source, target, teacher_force_ratio = 0.5):
    batch_size = target.shape[1]
    target_len = target.shape[0]

    trg_vocab_size = self.decoder.output_dim

    outputs = torch.zeros(target_len, batch_size, trg_vocab_size).to(device)

    h = self.encoder(source)

    x = target[0,:]

    for t in range(1, target_len):
      output, h = self.decoder(x, h)
      outputs[t] = output
      best_guess = output.argmax(1)
      x = target[t] if torch.rand(1) < teacher_force_ratio else best_guess

    return outputs

"""## Train RNN Model"""

epoches = 10


train_loss_list, test_loss_list = [], []

torch.manual_seed(64)
torch.cuda.manual_seed(64)
rnn_encoder = RNNEncoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, dropout_preb).to(device)
rnn_decoder = RNNDecoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dropout_preb).to(device)
rnn_model = RNNSeq2Seq(rnn_encoder, rnn_decoder).to(device)

optimizer = torch.optim.Adam(rnn_model.parameters(), lr = 1e-3)

start_time = timer()
torch.manual_seed(64)
torch.cuda.manual_seed(64)
for epoch in tqdm(range(epoches)):
  print(f'Epoch: {epoch+1} / {epoches}')

  train_loss = train(rnn_model, train_iter, loss_fn, optimizer, device)
  test_loss = test_loop(rnn_model, test_iter, loss_fn, device)

  train_loss_list.append(train_loss.item())
  test_loss_list.append(test_loss.item())

  print(f"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}")
  print()
  # print(f"Train Loss: {train_loss:.4f}")
end_time = timer()

print(f'Total Exe Time: {(end_time - start_time)} Sec')

plot_graph(train_loss_list, test_loss_list)

"""# B

## Hyperparameter training
### for 3 number of encoder and decoder system ram crashed so there for I avoid number 3 for encoder and decoder
"""

#Hypermeter
embedding_size = [16, 64]
# decoder_embedding_size = 64
hidden_size_ = [16, 64]

hyper_params = [(es, hs) for es in embedding_size for hs in hidden_size_]

"""## LSTM"""

epoches = 10

cur_iter,total_iter = 1, len(embedding_size)*len(hidden_size_)
for h_p in hyper_params:
  print()
  print(f"iter: {cur_iter} / {total_iter}")
  print(f"Tuning with --- encoder embedding size: {h_p[0]}, decoder embedding size: {h_p[0]}, hidden size: {h_p[1]}")
  train_loss_list, test_loss_list = [], []

  encoder_embedding_size = h_p[0]
  decoder_embedding_size = h_p[0]
  hidden_size = h_p[1]

  torch.manual_seed(64)
  torch.cuda.manual_seed(64)
  lstm_encoder = LSTMEncoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, dropout_preb).to(device)
  lstm_decoder = LSTMDecoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dropout_preb).to(device)
  lstm_model = LSTMSeq2Seq(lstm_encoder, lstm_decoder).to(device)

  optimizer = torch.optim.Adam(lstm_model.parameters(), lr = 1e-2)

  start_time = timer()
  torch.manual_seed(64)
  torch.cuda.manual_seed(64)
  for epoch in tqdm(range(epoches)):
    print(f'Epoch: {epoch+1} / {epoches}')

    train_loss = train(lstm_model, val_iter, loss_fn, optimizer, device)
    test_loss = test_loop(lstm_model, test_iter, loss_fn, device)

    train_loss_list.append(train_loss.item())
    test_loss_list.append(test_loss.item())

    print(f"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}")
    print()
    # print(f"Train Loss: {train_loss:.4f}")
  end_time = timer()

  print(f'Total Exe Time: {(end_time - start_time)} Sec')

  cur_iter += 1
  plot_graph(train_loss_list, test_loss_list)

"""## RNN"""

epoches = 10

cur_iter,total_iter = 1, len(embedding_size)*len(hidden_size_)
for h_p in hyper_params:
  print()
  print(f"iter: {cur_iter} / {total_iter}")
  print(f"Tuning with --- encoder embedding size: {h_p[0]}, decoder embedding size: {h_p[0]}, hidden size: {h_p[1]}")
  train_loss_list, test_loss_list = [], []

  encoder_embedding_size = h_p[0]
  decoder_embedding_size = h_p[0]
  hidden_size = h_p[1]

  torch.manual_seed(64)
  torch.cuda.manual_seed(64)
  rnn_encoder = RNNEncoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, dropout_preb).to(device)
  rnn_decoder = RNNDecoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dropout_preb).to(device)
  rnn_model = RNNSeq2Seq(rnn_encoder, rnn_decoder).to(device)

  optimizer = torch.optim.Adam(lstm_model.parameters(), lr = 1e-3)

  start_time = timer()
  torch.manual_seed(64)
  torch.cuda.manual_seed(64)
  for epoch in tqdm(range(epoches)):
    print(f'Epoch: {epoch+1} / {epoches}')

    train_loss = train(lstm_model, val_iter, loss_fn, optimizer, device)
    test_loss = test_loop(lstm_model, test_iter, loss_fn, device)

    train_loss_list.append(train_loss.item())
    test_loss_list.append(test_loss.item())

    print(f"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}")
    print()
    # print(f"Train Loss: {train_loss:.4f}")
  end_time = timer()

  print(f'Total Exe Time: {(end_time - start_time)} Sec')

  cur_iter += 1
  plot_graph(train_loss_list, test_loss_list)

"""# C

## Question 1: RNN take less time than LSTM
### LSTMs are a particular kind of RNN created to solve the vanishing gradient issue that might arise in conventional RNNs. To better capture long-range dependencies in sequential data, LSTMs employ a more intricate structure with gating features. In contrast to more straightforward RNNs, LSTMs may need more training data and longer training times due to their higher complexity.

## Question 2: Dropout give better output
### Yes it reduces the chance of overfitting

### Proof
"""

# for proof use rnn because lstm use to avoid overfitting in rnn

class RNNEncoder(nn.Module):
  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):
    super().__init__()
    self.input_size = input_size
    self.embedding_size = embedding_size
    self.hidden_size = hidden_size
    self.num_layers = num_layers
    # self.dropout = nn.Dropout(p)
    self.embedding = nn.Embedding(input_size, embedding_size)
    self.rnn = nn.RNN(embedding_size, hidden_size, num_layers)
    

  def forward(self, x):
    embedding = self.embedding(x)
    ot, h = self.rnn(embedding)

    return h


class RNNDecoder(nn.Module):
  def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p):
    super().__init__()
    self.input_size = input_size
    self.embedding_size = embedding_size
    self.hidden_size = hidden_size
    self.output_dim = output_size
    self.num_layers = num_layers
    # self.dropout = nn.Dropout(p)

    self.embedding = nn.Embedding(output_size, embedding_size)
    self.rnn = nn.RNN(embedding_size, hidden_size, num_layers)
    self.fc = nn.Linear(hidden_size, output_size)

  def forward(self, x, h):

    x = x.unsqueeze(0)

    embedding = self.embedding(x)

    ot, h = self.rnn(embedding, h)

    predict = self.fc(ot.squeeze(0))

    # predict = predict.squeeze(0)

    return predict, h


class RNNSeq2Seq(nn.Module):
  def __init__(self, encoder, decoder):
    super().__init__()
    self.encoder = encoder
    self.decoder = decoder

  def forward(self, source, target, teacher_force_ratio = 0.5):
    batch_size = target.shape[1]
    target_len = target.shape[0]

    trg_vocab_size = self.decoder.output_dim

    outputs = torch.zeros(target_len, batch_size, trg_vocab_size).to(device)

    h = self.encoder(source)

    x = target[0,:]

    for t in range(1, target_len):
      output, h = self.decoder(x, h)
      outputs[t] = output
      best_guess = output.argmax(1)
      x = target[t] if torch.rand(1) < teacher_force_ratio else best_guess

    return outputs

# train model


load_model = False
input_size_encoder = len(source_field.vocab)
input_size_decoder = len(target_field.vocab)
output_size = len(target_field.vocab)
encoder_embedding_size = 64
decoder_embedding_size = 64
hidden_size = 64
num_layers = 1
dropout_preb = 0.3



epoches = 10


train_loss_list, test_loss_list = [], []

torch.manual_seed(64)
torch.cuda.manual_seed(64)
rnn_encoder = RNNEncoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, dropout_preb).to(device)
rnn_decoder = RNNDecoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dropout_preb).to(device)
rnn_model = RNNSeq2Seq(rnn_encoder, rnn_decoder).to(device)

optimizer = torch.optim.Adam(rnn_model.parameters(), lr = 1e-3)

start_time = timer()
torch.manual_seed(64)
torch.cuda.manual_seed(64)
for epoch in tqdm(range(epoches)):
  print(f'Epoch: {epoch+1} / {epoches}')

  train_loss = train(rnn_model, train_iter, loss_fn, optimizer, device)
  test_loss = test_loop(rnn_model, test_iter, loss_fn, device)

  train_loss_list.append(train_loss.item())
  test_loss_list.append(test_loss.item())

  print(f"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}")
  print()
  # print(f"Train Loss: {train_loss:.4f}")
end_time = timer()

print(f'Total Exe Time: {(end_time - start_time)} Sec')

plot_graph(train_loss_list, test_loss_list)

"""## Question 3: 
### RNN- and LSTM-based seq2seq models' performance can be significantly impacted by the size of the hidden layer. With larger hidden layer sizes, the model can capture more intricate patterns in the data, whereas with smaller hidden layer sizes, the model may be less capable of modelling and may be less able to catch fine-grained characteristics. When the size of the hidden layer is too small, the model could have trouble capturing the nuances of the input data, which could result in poorer accuracy or subpar performance. But bigger hidden layer sizes also call for greater computational power and might be more prone to overfitting, particularly if the dataset is tiny.

## proof LSTM

### Hidden size 8
"""

print("Hidden size : 8")
epoches = 10
encoder_embedding_size = 64
decoder_embedding_size = 64
hidden_size = 8

train_loss_list, test_loss_list = [], []

torch.manual_seed(64)
torch.cuda.manual_seed(64)
lstm_encoder = LSTMEncoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, dropout_preb).to(device)
lstm_decoder = LSTMDecoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dropout_preb).to(device)
lstm_model = LSTMSeq2Seq(lstm_encoder, lstm_decoder).to(device)

optimizer = torch.optim.Adam(lstm_model.parameters(), lr = 1e-2)

start_time = timer()
torch.manual_seed(64)
torch.cuda.manual_seed(64)
for epoch in tqdm(range(epoches)):
  print(f'Epoch: {epoch+1} / {epoches}')

  train_loss = train(lstm_model, train_iter, loss_fn, optimizer, device)
  test_loss = test_loop(lstm_model, test_iter, loss_fn, device)

  train_loss_list.append(train_loss.item())
  test_loss_list.append(test_loss.item())

  print(f"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}")
  print()
  # print(f"Train Loss: {train_loss:.4f}")
end_time = timer()

print(f'Total Exe Time: {(end_time - start_time)} Sec')

plot_graph(train_loss_list, test_loss_list)

"""### Hidden size 16"""

print("Hidden size : 16")
epoches = 10
hidden_size = 16

train_loss_list, test_loss_list = [], []

torch.manual_seed(64)
torch.cuda.manual_seed(64)
lstm_encoder = LSTMEncoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, dropout_preb).to(device)
lstm_decoder = LSTMDecoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dropout_preb).to(device)
lstm_model = LSTMSeq2Seq(lstm_encoder, lstm_decoder).to(device)

optimizer = torch.optim.Adam(lstm_model.parameters(), lr = 1e-2)

start_time = timer()
torch.manual_seed(64)
torch.cuda.manual_seed(64)
for epoch in tqdm(range(epoches)):
  print(f'Epoch: {epoch+1} / {epoches}')

  train_loss = train(lstm_model, train_iter, loss_fn, optimizer, device)
  test_loss = test_loop(lstm_model, test_iter, loss_fn, device)

  train_loss_list.append(train_loss.item())
  test_loss_list.append(test_loss.item())

  print(f"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}")
  print()
  # print(f"Train Loss: {train_loss:.4f}")
end_time = timer()

print(f'Total Exe Time: {(end_time - start_time)} Sec')

plot_graph(train_loss_list, test_loss_list)

"""### Hidden size 32"""

print("Hidden size : 32")
epoches = 10
hidden_size = 32

train_loss_list, test_loss_list = [], []

torch.manual_seed(64)
torch.cuda.manual_seed(64)
lstm_encoder = LSTMEncoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, dropout_preb).to(device)
lstm_decoder = LSTMDecoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dropout_preb).to(device)
lstm_model = LSTMSeq2Seq(lstm_encoder, lstm_decoder).to(device)

optimizer = torch.optim.Adam(lstm_model.parameters(), lr = 1e-2)

start_time = timer()
torch.manual_seed(64)
torch.cuda.manual_seed(64)
for epoch in tqdm(range(epoches)):
  print(f'Epoch: {epoch+1} / {epoches}')

  train_loss = train(lstm_model, train_iter, loss_fn, optimizer, device)
  test_loss = test_loop(lstm_model, test_iter, loss_fn, device)

  train_loss_list.append(train_loss.item())
  test_loss_list.append(test_loss.item())

  print(f"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}")
  print()
  # print(f"Train Loss: {train_loss:.4f}")
end_time = timer()

print(f'Total Exe Time: {(end_time - start_time)} Sec')

plot_graph(train_loss_list, test_loss_list)

"""### Hidden size 64"""

print("Hidden size : 64")
epoches = 10
hidden_size = 64

train_loss_list, test_loss_list = [], []

torch.manual_seed(64)
torch.cuda.manual_seed(64)
lstm_encoder = LSTMEncoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, dropout_preb).to(device)
lstm_decoder = LSTMDecoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dropout_preb).to(device)
lstm_model = LSTMSeq2Seq(lstm_encoder, lstm_decoder).to(device)

optimizer = torch.optim.Adam(lstm_model.parameters(), lr = 1e-2)

start_time = timer()
torch.manual_seed(64)
torch.cuda.manual_seed(64)
for epoch in tqdm(range(epoches)):
  print(f'Epoch: {epoch+1} / {epoches}')

  train_loss = train(lstm_model, train_iter, loss_fn, optimizer, device)
  test_loss = test_loop(lstm_model, test_iter, loss_fn, device)

  train_loss_list.append(train_loss.item())
  test_loss_list.append(test_loss.item())

  print(f"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}")
  print()
  # print(f"Train Loss: {train_loss:.4f}")
end_time = timer()

print(f'Total Exe Time: {(end_time - start_time)} Sec')

plot_graph(train_loss_list, test_loss_list)

"""## Proof RNN

### Hidden size 8
"""

epoches = 10
hidden_size = 8

train_loss_list, test_loss_list = [], []

torch.manual_seed(64)
torch.cuda.manual_seed(64)
rnn_encoder = RNNEncoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, dropout_preb).to(device)
rnn_decoder = RNNDecoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dropout_preb).to(device)
rnn_model = RNNSeq2Seq(rnn_encoder, rnn_decoder).to(device)

optimizer = torch.optim.Adam(rnn_model.parameters(), lr = 1e-3)

start_time = timer()
torch.manual_seed(64)
torch.cuda.manual_seed(64)
for epoch in tqdm(range(epoches)):
  print(f'Epoch: {epoch+1} / {epoches}')

  train_loss = train(rnn_model, train_iter, loss_fn, optimizer, device)
  test_loss = test_loop(rnn_model, test_iter, loss_fn, device)

  train_loss_list.append(train_loss.item())
  test_loss_list.append(test_loss.item())

  print(f"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}")
  print()
  # print(f"Train Loss: {train_loss:.4f}")
end_time = timer()

print(f'Total Exe Time: {(end_time - start_time)} Sec')

plot_graph(train_loss_list, test_loss_list)

"""### Hidden size 16"""

epoches = 10
hidden_size = 16

train_loss_list, test_loss_list = [], []

torch.manual_seed(64)
torch.cuda.manual_seed(64)
rnn_encoder = RNNEncoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, dropout_preb).to(device)
rnn_decoder = RNNDecoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dropout_preb).to(device)
rnn_model = RNNSeq2Seq(rnn_encoder, rnn_decoder).to(device)

optimizer = torch.optim.Adam(rnn_model.parameters(), lr = 1e-3)

start_time = timer()
torch.manual_seed(64)
torch.cuda.manual_seed(64)
for epoch in tqdm(range(epoches)):
  print(f'Epoch: {epoch+1} / {epoches}')

  train_loss = train(rnn_model, train_iter, loss_fn, optimizer, device)
  test_loss = test_loop(rnn_model, test_iter, loss_fn, device)

  train_loss_list.append(train_loss.item())
  test_loss_list.append(test_loss.item())

  print(f"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}")
  print()
  # print(f"Train Loss: {train_loss:.4f}")
end_time = timer()

print(f'Total Exe Time: {(end_time - start_time)} Sec')

plot_graph(train_loss_list, test_loss_list)

"""### Hidden size 32"""

epoches = 10
hidden_size = 32

train_loss_list, test_loss_list = [], []

torch.manual_seed(64)
torch.cuda.manual_seed(64)
rnn_encoder = RNNEncoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, dropout_preb).to(device)
rnn_decoder = RNNDecoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dropout_preb).to(device)
rnn_model = RNNSeq2Seq(rnn_encoder, rnn_decoder).to(device)

optimizer = torch.optim.Adam(rnn_model.parameters(), lr = 1e-3)

start_time = timer()
torch.manual_seed(64)
torch.cuda.manual_seed(64)
for epoch in tqdm(range(epoches)):
  print(f'Epoch: {epoch+1} / {epoches}')

  train_loss = train(rnn_model, train_iter, loss_fn, optimizer, device)
  test_loss = test_loop(rnn_model, test_iter, loss_fn, device)

  train_loss_list.append(train_loss.item())
  test_loss_list.append(test_loss.item())

  print(f"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}")
  print()
  # print(f"Train Loss: {train_loss:.4f}")
end_time = timer()

print(f'Total Exe Time: {(end_time - start_time)} Sec')

plot_graph(train_loss_list, test_loss_list)

"""### Hidden size 64"""

epoches = 10
hidden_size = 64

train_loss_list, test_loss_list = [], []

torch.manual_seed(64)
torch.cuda.manual_seed(64)
rnn_encoder = RNNEncoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, dropout_preb).to(device)
rnn_decoder = RNNDecoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dropout_preb).to(device)
rnn_model = RNNSeq2Seq(rnn_encoder, rnn_decoder).to(device)

optimizer = torch.optim.Adam(rnn_model.parameters(), lr = 1e-3)

start_time = timer()
torch.manual_seed(64)
torch.cuda.manual_seed(64)
for epoch in tqdm(range(epoches)):
  print(f'Epoch: {epoch+1} / {epoches}')

  train_loss = train(rnn_model, train_iter, loss_fn, optimizer, device)
  test_loss = test_loop(rnn_model, test_iter, loss_fn, device)

  train_loss_list.append(train_loss.item())
  test_loss_list.append(test_loss.item())

  print(f"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}")
  print()
  # print(f"Train Loss: {train_loss:.4f}")
end_time = timer()

print(f'Total Exe Time: {(end_time - start_time)} Sec')

plot_graph(train_loss_list, test_loss_list)

"""# D

## LSTM with Attention
"""

# encoder
class ATEncoder(nn.Module):
  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):
    super().__init__()
    self.input_size = input_size
    self.hidden_size = hidden_size
    self.num_layers = num_layers
    self.dropout = nn.Dropout(p)
    self.embedding = nn.Embedding(input_size, embedding_size)
    self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=True)

    self.fc_h = nn.Linear(hidden_size*2, hidden_size)
    self.fc_c = nn.Linear(hidden_size*2, hidden_size)
    

  def forward(self, x):
    embedding = self.dropout(self.embedding(x))
    es, (h, c) = self.lstm(embedding)

    h = self.fc_h(torch.cat((h[0:1], h[1:2]), dim=2))
    c = self.fc_c(torch.cat((c[0:1], c[1:2]), dim=2))

    return es, h, c


# decoder
class ATDecoder(nn.Module):
  def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p):
    super().__init__()
    self.hidden_size = hidden_size
    self.output_dim = output_size
    self.num_layers = num_layers
    self.dropout = nn.Dropout(p)
    self.embedding = nn.Embedding(output_size, embedding_size)
    self.lstm = nn.LSTM(hidden_size*2 + embedding_size, hidden_size, num_layers)

    self.energy = nn.Linear(hidden_size*3, 1)
    self.softmax = nn.Softmax(dim=0)
    self.relu = nn.ReLU()


    self.fc = nn.Linear(hidden_size, output_size)

  def forward(self, x, es, h, c):

    x = x.unsqueeze(0)

    embedding = self.dropout(self.embedding(x))

    sequence_length = es.shape[0]
    h_reshaped = h.repeat(sequence_length, 1, 1)

    energy = self.relu(self.energy(torch.cat((h_reshaped, es), dim = 2)))

    attention = self.softmax(energy)

    attention = attention.permute(1, 2, 0)

    es = es.permute(1,0,2)

    context_vector = torch.bmm(attention, es).permute(1, 0, 2)

    lstm_input = torch.cat((context_vector, embedding), dim=2)

    ot, (h, c) = self.lstm(lstm_input, (h, c))

    predict = self.fc(ot.squeeze(0))

    # predict = predict.squeeze(0)

    return predict, h, c


# Seq2Seq
class ATSeq2Seq(nn.Module):
  def __init__(self, encoder, decoder):
    super().__init__()
    self.encoder = encoder
    self.decoder = decoder

  def forward(self, source, target, teacher_force_ratio = 0.5):
    batch_size = target.shape[1]
    target_len = target.shape[0]

    trg_vocab_size = self.decoder.output_dim

    outputs = torch.zeros(target_len, batch_size, trg_vocab_size).to(device)

    es, h, c = self.encoder(source)

    x = target[0,:]

    for t in range(1, target_len):
      output, h, c = self.decoder(x, es, h, c)
      outputs[t] = output
      best_guess = output.argmax(1)

      x = target[t] if random.random() < teacher_force_ratio else best_guess

    return outputs

"""## Train Attention Model"""

load_model = False
input_size_encoder = len(source_field.vocab)
input_size_decoder = len(target_field.vocab)
output_size = len(target_field.vocab)
encoder_embedding_size = 16
decoder_embedding_size = 16
hidden_size = 32
num_layers = 1
dropout_preb = 0.3

epoches = 10


train_loss_list, test_loss_list = [], []

torch.manual_seed(64)
torch.cuda.manual_seed(64)
at_encoder = ATEncoder(input_size_encoder, encoder_embedding_size, hidden_size, num_layers, dropout_preb).to(device)
at_decoder = ATDecoder(input_size_decoder, decoder_embedding_size, hidden_size, output_size, num_layers, dropout_preb).to(device)
at_model = ATSeq2Seq(at_encoder, at_decoder).to(device)

optimizer = torch.optim.Adam(at_model.parameters(), lr = 1e-2)

start_time = timer()
torch.manual_seed(64)
torch.cuda.manual_seed(64)
for epoch in tqdm(range(epoches)):
  print(f'Epoch: {epoch+1} / {epoches}')

  train_loss = train(at_model, train_iter, loss_fn, optimizer, device)
  test_loss = test_loop(at_model, test_iter, loss_fn, device)

  train_loss_list.append(train_loss.item())
  test_loss_list.append(test_loss.item())

  print(f"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}")
  print()
  # print(f"Train Loss: {train_loss:.4f}")
end_time = timer()

print(f'Total Exe Time: {(end_time - start_time)} Sec')

plot_graph(train_loss_list, test_loss_list)